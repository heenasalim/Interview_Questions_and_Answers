Managed_table


pig -Dudf.import.list=com.searshc.supplychain.idrp.udf  
-m /appl/conf/hdidrp/prod/USER.cfg 
-m /appl/conf/hdidrp/prod/PROJECT.cfg 
-m /appl/hdidrp/pig/params/shared/common.param 
-m /appl/hdidrp/pig/params/item_eligibility/smith__idrp_eligible_item_current/perform_item_eligibility_smith__idrp_eligible_item_current.param 
-m work__idrp_eligible_item_current_part_4.schema 
-m smith__idrp_eligible_item_current.schema -p batchid=4047 -f perform_item_eligibility_smith__idrp_eligible_item_current_4.pig



create table heena_practice.managed_table
  ( dept_id smallint,
  dept_name varchar(20),
  name varchar(20), 
  address string ,
  salary double)
  row format delimited
  fields terminated by '|';
  
  
  create table heena_practice.temporary
  ( dept_id smallint,
  dept_name varchar(20),
  name varchar(20), 
  address string ,
  salary double)
  row format delimited
  fields terminated by '|';
  
load data local  inpath "/home/auto/hshaik0/data/department.txt" into table heena_practice.temporary; 
 
/user/hive/warehouse/heena_practice.db/managed_table

Loading the data from local filesystem
load data local  inpath "/home/auto/hshaik0/data/department.txt" into table heena_practice.managed_table;

Loading the data from HDFS filesystem
load data inpath "/user/hshaik0/department.txt" into table heena_practice.managed_table;

data will be move from /user/hshaik0 to /user/hive/warehouse/heena_practice.db/managed_table
hence data will not be available in actual data path

select * from heena_practice.managed_table where dept_id=1;

Inserting data into the table :-

INSERT OVERWRITE TABLE heena_practice.managed_table select * from temporary;

select * from heena_practice.managed_table;
===============================================================================

External Table

create external table heena_practice.external_table(book_id int,book_name varchar(20),book_price int)
row format delimited 
fields terminated by "|"
location "/user/hshaik0/information_library/";

Loading the data from local filesystem
load data local  inpath "/home/auto/hshaik0/data/books.txt" into table heena_practice.external_table;


Loading the data from HDFS filesystem
load data inpath "/user/hshaik0/books.txt" into table heena_practice.external_table;

By loading data from hdfs the copy of the data move in the /user/hive/warehouse and you will not loose data

  create table heena_practice.temporary1
  ( dept_id smallint,
  dept_name varchar(20),
  salary double)
  row format delimited
  fields terminated by '|';
  
load data local inpath "/home/auto/hshaik0/data/books.txt" into table heena_practice.temporary1;

Inserting data into the table :-
INSERT OVERWRITE TABLE heena_practice.external_table select * from temporary1;

select * from heena_practice.external_table

==============================================================
ALTER TABLE book_store RENAME to book_store1
ALTER TABLE book_store ADD COLUMNS(new_price int);
alter table book_store change new_price  updated_price double;
alter table book_store change book_price book_price double;

===============================================================================



CLUSTERING 
1>  create table heena_practice.temporary1
  ( dept_id smallint,
  dept_name varchar(20),
  salary double)
  row format delimited
  fields terminated by '|';
  
2> load data local inpath "/home/auto/hshaik0/data/books.txt" into table heena_practice.temporary1;


drop table heena_practice.user_inf;

dfs -rm -r /user/hive/warehouse/heena_practice.db/user_inf/*;

3> 
CREATE EXTERNAL TABLE heena_practice.user_inf( user_id BIGINT,firstname STRING, salary DOUBLE) 
CLUSTERED BY(user_id) INTO 9 BUCKETS
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|';
--STORED AS TEXTFILE;

The bucketed column name should be inside table definition

load data local inpath "/home/auto/hshaik0/data/books.txt" into table heena_practice.user_inf;

do not load data instead override from temporaray table here 

4> 
insert overwrite table heena_practice.user_inf select dept_id,dept_name,salary from heena_practice.temporary1;

select * from  heena_practice.user_inf;

dfs -ls /user/hive/warehouse/heena_practice.db/user_inf/;

19/04/15 16:05:44 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.0-hadoop2
-rwxrwxrwx   3 hshaik0 hdfs 40B 2019-04-15 16:05 /user/hive/warehouse/heena_practice.db/user_inf/books.txt



===========================================================

PARTITIONING:

CREATE TABLE heena_practice.single_partitioned(id INT, name STRING, dept STRING, yoj DOUBLE)
PARTITIONED BY (year STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

			load data local inpath "/home/auto/hshaik0/data/single_partitioned.txt" into table heena_practice.single_partitioned;

			here data will be go into partition directory hence we need to load partition data directory


load data local inpath  "/home/auto/hshaik0/data/books.txt" overwrite into table heena_practice.single_partitioned
partition (year='2008');

			Loading data to table heena_practice.single_partitioned partition (year=180706)
			Partition heena_practice.single_partitioned{year=180706} stats: [numFiles=2, numRows=0, totalSize=80, rawDataSize=0]
			OK
			
			
select * from heena_practice.single_partitioned;

Partition directory
19/04/15 15:54:36 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.0-hadoop2
drwxrwxrwx   - hshaik0 hdfs 0B 2019-04-15 15:52 /user/hive/warehouse/heena_practice.db/single_partitioned/year=2008/books.txt
-bash-4.1$



==============================================================================================================
DYNAMIC PARTITIONING	
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;
set hive.mapred.mode=nonstrict;

-- Set the maximum number of reducers to the same number of buckets specified
-- in the table metadata (i.e. 31). See below create MASTER table with buckets
set map.reduce.tasks=31;

set hive.enforce.bucketing=true;
set hive.exec.dynamic.partition.mode=nonstrict;

drop table heena_practice.election;
create external table heena_practice.election(
id Int,
name String,
address String,
card_no Int,
country String,
state String
)
row format delimited
fields terminated by '|'
location '/user/hshaik0/election/';


load data local inpath '/home/auto/hshaik0/data/election.txt' overwrite into table heena_practice.election;
dfs -rm /user/hshaik0/voters_table
create external table heena_practice.dynamic_partitioned_election
(
id Int,
name String,
address String,
card_no Int)
partitioned by(country String,state String)
clustered by (card_no) into 4 buckets
row format delimited
location '/user/hshaik0/voters_table';
insert overwrite table heena_practice.dynamic_partitioned_election partition(state,city) select * from heena_practice.election;


select * from heena_practice.dynamic_partitioned_election;


-rw-r--r--   3 hshaik0 hshaik0 2B 2019-04-19 11:18 /user/hshaik0/voters_table/.hive-staging_hive_2019-04-19_11-18-10_233_159047044785738848-1/-ext-10001/tmpstats-2
-rwxrwxrwx   3 hshaik0 hshaik0 21B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Austrelia/city=Victoria/000000_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Austrelia/city=Victoria/000001_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Austrelia/city=Victoria/000002_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Austrelia/city=Victoria/000003_0
-rwxrwxrwx   3 hshaik0 hshaik0 24B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Canada/city=Ontario/000000_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Canada/city=Ontario/000001_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Canada/city=Ontario/000002_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=Canada/city=Ontario/000003_0
-rwxrwxrwx   3 hshaik0 hshaik0 22B 2019-04-19 11:18 /user/hshaik0/voters_table/state=China/city=Henan/000000_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=China/city=Henan/000001_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=China/city=Henan/000002_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=China/city=Henan/000003_0
-rwxrwxrwx   3 hshaik0 hshaik0 43B 2019-04-19 11:18 /user/hshaik0/voters_table/state=India/city=Maharashtra/000000_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=India/city=Maharashtra/000001_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=India/city=Maharashtra/000002_0
-rwxrwxrwx   3 hshaik0 hshaik0 0B 2019-04-19 11:18 /user/hshaik0/voters_table/state=India/city=Maharashtra/000003_0

============================================================================================

SIMPLE PARTITIONING AND CLUSTERING or STATIC PARTITIONING

1:

create external table heena_practice.static_partitioned_election
(
id Int,
name String,
address String,
card_no Int,
country String,
state String)
partitioned by(division_no String,maths_id String)
clustered by (card_no) into 4 buckets
row format delimited
location '/user/hshaik0/voters_table';   -- hive-warehouse

drop table heena_practice.election;
create external table heena_practice.election(
id Int,
name String,
address String,
card_no Int,
country String,
state String
)
row format delimited
fields terminated by '|'
location '/user/hshaik0/election/';

insert overwrite table heena_practice.static_partitioned_election partition(division_no = '1' ,maths_id  = '1000') select * from heena_practice.election where country = 'India';
insert overwrite table heena_practice.static_partitioned_election partition(division_no = '2' ,maths_id  = '2000') select * from heena_practice.election;
insert overwrite table heena_practice.static_partitioned_election partition(division_no = '1' ,maths_id  = '3000') select * from heena_practice.election;
insert overwrite table heena_practice.static_partitioned_election partition(division_no = '4' ,maths_id  = '1000') select * from heena_practice.election;
insert overwrite table heena_practice.static_partitioned_election partition(division_no = '9' ,maths_id  = '2000') select * from heena_practice.election;
insert overwrite table heena_practice.static_partitioned_election partition(division_no = '2' ,maths_id  = '3000') select * from heena_practice.election;

dfs -ls /user/hshaik0/voters_table/*

Found 2 items
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 12:47 /user/hshaik0/voters_table/division_no=1/maths_id=1000
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 12:48 /user/hshaik0/voters_table/division_no=1/maths_id=3000
Found 2 items
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 12:48 /user/hshaik0/voters_table/division_no=2/maths_id=2000
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 12:50 /user/hshaik0/voters_table/division_no=2/maths_id=3000
Found 1 items
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 12:48 /user/hshaik0/voters_table/division_no=4/maths_id=1000
Found 1 items
drwxrwxrwx   - hshaik0 hshaik0          0 2019-04-20 13:02 /user/hshaik0/voters_table/division_no=9/maths_id=2000

Heena won !!

Hive

"insert overwrite table gold__sales_sears_pos_tran partition (transaction_year_nbr = '$PROCESS_YEAR') select * from work__sales_sears_pos_tran"
alter table $GOLD_TABLE drop partition (data_center = '$DATA_CENTER');
alter table gold__marketing_price_sears add partition (price_status='current') location '/gold/marketing/price/sears/price_status=current/';
"alter table gold__sales_sears_pos_cancel_original_sale add if not exists partition (transaction_year_nbr=$PROCESS_YEAR);"
"alter table gold__sales_sears_pos_markdown add if not exists partition (transaction_year_nbr=$PROCESS_YEAR);"
hive -e "insert overwrite table gold__sales_sears_pos_tran_detail partition (transaction_year_nbr = '$PROCESS_YEAR') select * from work__sales_sears_pos_tran_detail"
hive -e "insert overwrite table gold__sales_sears_pos_tran partition (transaction_year_nbr = '$PROCESS_YEAR') select * from work__sales_sears_pos_tran"
hive -e "insert overwrite table gold__sales_sears_pos_payment partition (transaction_year_nbr = '$PROCESS_YEAR') select * from work__sales_sears_pos_payment"
hive -e "alter table gold__sales_sears_pos_tran add if not exists partition (transaction_year_nbr=$PROCESS_YEAR);"
hive -e "alter table gold__sales_sears_pos_tran_detail add if not exists partition (transaction_year_nbr=$PROCESS_YEAR);"
hive -e "alter table gold__sales_sears_pos_payment add if not exists partition (transaction_year_nbr=$PROCESS_YEAR);"
alter table gold__marketing_price_sears add partition (price_status='current') location '/gold/marketing/price/sears/price_status=current/';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2005') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2005';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2006') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2006';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2007') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2007';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2008') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2008';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2010') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2010';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2011') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2011';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2012') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2012';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2005') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2005';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2006') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2006';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2007') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2007';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2008') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2008';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2010') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2010';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2011') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2011';
alter table gold__sales_sears_pos_tax_exempt add partition (transaction_year_nbr='2012') location '/gold/transaction/pos/sears/tax_aud_s5_exempt/transaction_year_nbr=2012';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2013') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2013';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2003') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2003';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2009') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2009';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='1995') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=1995';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='1996') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=1996';
hive -e "insert overwrite table gold__sales_sears_pos_markdown partition (transaction_year_nbr = '$PROCESS_YEAR') select * from work__sales_sears_pos_markdown"
hive -e "alter table $GOLD_TABLE drop partition (data_center = '$DATA_CENTER');" | tee -a $LOG_FILE
Alter table to drop partition data_center=$DATA_CENTER ran successfully"
Alter table to drop partition data_center=$DATA_CENTER in error"
hive -e "insert overwrite table $GOLD_TABLE partition (data_center = '$DATA_CENTER') select to_date(from_unixtime(unix_timestamp())) load_dt,
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2013') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2013';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2003') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2003';
alter table gold__sales_sears_pos_tax_delivery add partition (transaction_year_nbr='2009') location '/gold/transaction/pos/sears/tax_aud_s5_delivery/transaction_year_nbr=2009';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2013') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2013';alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2003') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2003';
alter table gold__sales_sears_pos_tax_general add partition (transaction_year_nbr='2009') location '/gold/transaction/pos/sears/tax_aud_s5_general/transaction_year_nbr=2009';
	
	
	#hive -f common_tables.hql not necessary now

hive  -hiveconf CURRENT_DATE=`date +%Y%m%d` -hiveconf AVAIL_TARGET_TABLE=$AVAIL_TARGET_TABLE -hiveconf AVAIL_STAGING_INPUT_TABLE=$AVAIL_STAGING_INPUT_TABLE -hiveconf REF_SHC_LOCATION_INPUT_TABLE=$REF_SHC_LOCATION_INPUT_TABLE -f  SHC_WIFI_ACCESS_PT_AVAIL_hive.hql >>  SHC_WIFI_ACCESS_PT_AVAIL.log  2>&1



. /appl/conf/hdnet/netwatch_env.sh



##sh SHC_WIFI_ACCESS_PT_AVAIL_sqoop.sh

#hive -f common_tables.hql not necessary now

set hive.execution.engine=tez;

hive  -hiveconf CURRENT_DATE=20170413 -hiveconf AVAIL_TARGET_TABLE=$AVAIL_TARGET_TABLE -hiveconf AVAIL_STAGING_INPUT_TABLE=$AVAIL_STAGING_INPUT_TABLE -hiveconf REF_SHC_LOCATION_INPUT_TABLE=$REF_SHC_LOCATION_INPUT_TABLE -f  SHC_WIFI_ACCESS_PT_AVAIL_hive.hql >>  SHC_WIFI_ACCESS_PT_AVAIL_CURRENT_DATE.log  2>&1


. /appl/conf/hdnet/netwatch_env.sh

rm -f ./STR_ANLYTCS_MART_TBLS.SHC_WIFI_ACC_PT_AVAIL_MINUT.log
rm  -f ./Hive_scripts.txt

##sh SHC_WIFI_ACCESS_PT_AVAIL_sqoop.sh

#hive -f common_tables.hql not necessary now

 hive  -hiveconf CURRENT_DATE=`date +%Y%m%d` -hiveconf AVAIL_MINUT_TARGET_TABLE=$AVAIL_MINUT_TARGET_TABLE -hiveconf AVAIL_STAGING_INPUT_TABLE=$AVAIL_STAGING_INPUT_TABLE -hiveconf LU_DEJ_MINUT_ID_TABLE=$LU_DEJ_MINUT_ID_TABLE  -f SHC_WIFI_ACC_PT_AVAIL_MINUT_hive.hql >> ./STR_ANLYTCS_MART_TBLS.SHC_WIFI_ACC_PT_AVAIL_MINUT.log  2>&1

CREATE TABLE IF NOT EXISTS updated_values_minut  AS select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr ,TRGT.ACCESS_PT_MINUT_ID ,a.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,CURRENT_TIMESTAMP as mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT,MINUT_A a WHERE TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID AND TRGT.LOCN_NBR=a.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT  AND  TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID;

CREATE TABLE IF NOT EXISTS  SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A_without_map as select  TRGT.ACCESS_PT_ID,TRGT.ACCESS_PT_STAT_DT,TRGT.LOCN_NBR,TRGT.ACCESS_PT_MINUT_ID,a.access_pt_unavl_ind,TRGT.dataset_id,TRGT.creat_ts,a.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT LEFT JOIN MINUT_A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID);

CREATE TABLE IF NOT EXISTS  SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A as select /*+ MAPJOIN(a) */ TRGT.ACCESS_PT_ID,TRGT.ACCESS_PT_STAT_DT,TRGT.LOCN_NBR,TRGT.ACCESS_PT_MINUT_ID,a.access_pt_unavl_ind,TRGT.dataset_id,TRGT.creat_ts,a.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT LEFT JOIN MINUT_A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID);

CREATE TABLE IF NOT EXISTS non_updated_null_rows_minut AS SELECT * from SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A WHERE access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS non_updated_rows_minut as select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr,TRGT.ACCESS_PT_MINUT_ID,TRGT.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,TRGT.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT, non_updated_null_rows_minut r WHERE TRGT.ACCESS_PT_ID=r.ACCESS_PT_ID AND TRGT.LOCN_NBR=r.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=r.ACCESS_PT_STAT_DT AND TRGT.ACCESS_PT_MINUT_ID=r.ACCESS_PT_MINUT_ID -- AND TRGT.creat_ts=r.creat_ts AND TRGT.dataset_id=r.dataset_id  comment;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_MINUT_AVAIL_right_join_A AS select a.ACCESS_PT_ID,a.LOCN_NBR,a.ACCESS_PT_STAT_DT,a.ACCESS_PT_MINUT_ID,TRGT.access_pt_unavl_ind,a.dataset_id,a.creat_ts,TRGT.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT RIGHT JOIN MINUT_A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT  AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID);

CREATE TABLE IF NOT EXISTS insert_null_rows_minut AS SELECT * FROM SHC_WIFI_ACCESS_PT_MINUT_AVAIL_right_join_A where access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS INSERT_FINAL_MINUT AS SELECT  a.access_pt_id ,a.access_pt_stat_dt,a.locn_nbr ,a.ACCESS_PT_MINUT_ID ,a.access_pt_unavl_ind,a.dataset_id,a.creat_ts ,a.mod_ts FROM MINUT_A a,insert_null_rows_minut i WHERE a.ACCESS_PT_ID=i.ACCESS_PT_ID AND a.LOCN_NBR=i.LOCN_NBR AND a.ACCESS_PT_STAT_DT=i.ACCESS_PT_STAT_DT AND a.ACCESS_PT_MINUT_ID=i.ACCESS_PT_MINUT_ID AND a.creat_ts=i.creat_ts;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_MINUT_AVAIL_MERGE  AS  select * from updated_values_minut union all select distinct *  from non_updated_rows_minut  UNION ALL SELECT  distinct * FROM INSERT_FINAL_MINUT;




CREATE TABLE  IF NOT EXISTS TMP_acc_pt_down_tm  as
 SELECT ROW_NUMBER() OVER(ORDER BY a.STAT_DT ,
   a.STR_NBR ,
   a.ACCESS_PT_NM ,
   a.ACCESS_PT_UNAVL_IND ,
   a.ACCESS_PT_UNAVL_MINUT_QTY ,a.OUTAGE_BEG_TM,a.OUTAGE_END_TM ) row_num,
   a.STAT_DT ,
   a.STR_NBR ,
   a.ACCESS_PT_NM ,
   a.ACCESS_PT_UNAVL_IND ,
   a.ACCESS_PT_UNAVL_MINUT_QTY ,
   CAST( from_unixtime(unix_timestamp(OUTAGE_BEG_TM),'dd-MM-yyyy HH:MM:SS0000') AS CHAR(20)) OUTAGE_BEG_TM,
   CAST( from_unixtime(unix_timestamp(OUTAGE_END_TM),'dd-MM-yyyy HH:MM:SS0000') AS CHAR(20)) OUTAGE_END_TM ,
   B.ACCESS_PT_MINUT_DESC START_MINUT_DESC,
   B.ACCESS_PT_MINUT_ID START_MINUT_ID,
   C.ACCESS_PT_MINUT_DESC END_MINUT_DESC,
   C.ACCESS_PT_MINUT_ID END_MINUT_ID
   FROM ${hiveconf:AVAIL_STAGING_INPUT_TABLE} a,
   ${hiveconf:LU_DEJ_MINUT_ID_TABLE} b,
   ${hiveconf:LU_DEJ_MINUT_ID_TABLE} c
   WHERE a.ACCESS_PT_UNAVL_MINUT_QTY >0
   AND  CAST( from_unixtime(unix_timestamp(OUTAGE_BEG_TM),'dd-MM-yyyy HH:MM:SS0000') AS CHAR(20)) = b.ACCESS_PT_MINUT_DESC
   AND  CAST( from_unixtime(unix_timestamp(OUTAGE_END_TM),'dd-MM-yyyy HH:MM:SS0000') AS CHAR(20)) = c.ACCESS_PT_MINUT_DESC;


    CREATE TABLE IF NOT EXISTS TMP_acc_pt_minut_brk_dn
    AS
     SELECT
     ACCESS_PT_ID,
     ACCESS_PT_STAT_DT,
     CAST(SUBSTR(LOCN_NBR,2) AS INT) LOCN_NBR,
     CAST(ACCESS_PT_MINUT_ID AS SMALLINT) ACCESS_PT_MINUT_ID,
     CAST(ACCESS_PT_UNAVL_IND AS CHAR(1) ) ACCESS_PT_UNAVL_IND,
     CAST(CURRENT_DATE AS INT) DATASET_ID,
     CURRENT_TIMESTAMP CREAT_TS,
     CURRENT_TIMESTAMP MOD_TS
     FROM
     (
      SELECT DISTINCT
      a.row_num,
      a.ACCESS_PT_NM ACCESS_PT_ID,
      a.STAT_DT ACCESS_PT_STAT_DT,
      a.STR_NBR LOCN_NBR,
      b.ACCESS_PT_MINUT_ID ACCESS_PT_MINUT_ID,
      '1' ACCESS_PT_UNAVL_IND
      FROM
      TMP_acc_pt_down_tm a,
      ${hiveconf:LU_DEJ_MINUT_ID_TABLE} b
      WHERE
      b.ACCESS_PT_MINUT_ID BETWEEN a.START_MINUT_ID AND a.end_MINUT_ID
     )a ;

CREATE TABLE IF NOT EXISTS MINUT_A  AS 
    SELECT
    ACCESS_PT_ID ,
    ACCESS_PT_STAT_DT,
    LOCN_NBR ,
    ACCESS_PT_MINUT_ID ,
    ACCESS_PT_UNAVL_IND ,
    DATASET_ID,
    CREAT_TS,
    MOD_TS
    FROM
    TMP_acc_pt_minut_brk_dn;




CREATE TABLE IF NOT EXISTS updated_values_minut  AS select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr ,TRGT.ACCESS_PT_MINUT_ID ,a.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,CURRENT_TIMESTAMP as mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT,MINUT_A a WHERE TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID AND TRGT.LOCN_NBR=a.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT  AND  TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID;

CREATE TABLE IF NOT EXISTS  SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A as select TRGT.ACCESS_PT_ID,TRGT.LOCN_NBR,TRGT.ACCESS_PT_STAT_DT,TRGT.ACCESS_PT_MINUT_ID,a.access_pt_unavl_ind,TRGT.dataset_id,TRGT.creat_ts,a.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT LEFT JOIN MINUT_A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID);

CREATE TABLE IF NOT EXISTS non_updated_null_rows_minut AS SELECT * from SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A WHERE access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS non_updated_rows as select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr,TRGT.ACCESS_PT_MINUT_ID,TRGT.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,TRGT.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT, non_updated_null_rows_minut r WHERE TRGT.ACCESS_PT_ID=r.ACCESS_PT_ID AND TRGT.LOCN_NBR=r.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=r.ACCESS_PT_STAT_DT AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID  AND TRGT.creat_ts=r.creat_ts AND TRGT.dataset_id=r.dataset_id;

CREATE TABLE IF NOT EXISTS UPDATED_FINAL_MINUT as select * from updated_values_minut union all select distinct *  from non_updated_rows;


CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_MINUT_AVAIL_right_join_A AS  select a.ACCESS_PT_ID,a.LOCN_NBR,a.ACCESS_PT_STAT_DT,a.ACCESS_PT_MINUT_ID,TRGT.access_pt_unavl_ind,a.dataset_id,a.creat_ts,TRGT.mod_ts FROM ${hiveconf:AVAIL_MINUT_TARGET_TABLE} TRGT RIGHT JOIN MINUT_A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT  AND TRGT.ACCESS_PT_MINUT_ID=a.ACCESS_PT_MINUT_ID);

CREATE TABLE IF NOT EXISTS insert_null_rows_minut AS SELECT * FROM SHC_WIFI_ACCESS_PT_MINUT_AVAIL_right_join_A where access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS INSERT_FINAL_MINUT AS SELECT  a.access_pt_id ,a.access_pt_stat_dt,a.locn_nbr ,a.ACCESS_PT_MINUT_ID ,a.access_pt_unavl_ind,a.dataset_id,a.creat_ts ,a.mod_ts FROM MINUT_A a,insert_null_rows_minut i WHERE a.ACCESS_PT_ID=i.ACCESS_PT_ID AND a.LOCN_NBR=i.LOCN_NBR AND a.ACCESS_PT_STAT_DT=i.ACCESS_PT_STAT_DT AND a.ACCESS_PT_MINUT_ID=i.ACCESS_PT_MINUT_ID AND a.creat_ts=i.creat_ts;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_MINUT_AVAIL_MERGE  AS  SELECT * FROM UPDATED_FINAL_MINUT UNION ALL SELECT * FROM INSERT_FINAL_MINUT;




    MERGE INTO STR_ANLYTCS_MART_TBLS.SHC_WIFI_ACC_PT_AVAIL_MINUT TRGT
    USING (

        SELECT
        ACCESS_PT_ID ,
        ACCESS_PT_STAT_DT ,
        LOCN_NBR ,
        ACCESS_PT_MINUT_ID ,
        ACCESS_PT_UNAVL_IND ,
        DATASET_ID,
        CREAT_TS,
        MOD_TS
        FROM
        TMP_acc_pt_minut_brk_dn
        ) A
    ON TRGT.ACCESS_PT_ID=A.ACCESS_PT_ID
    AND (TRGT.ACCESS_PT_STAT_DT=A.ACCESS_PT_STAT_DT)
  AND (TRGT.LOCN_NBR=A.LOCN_NBR)
  AND (TRGT.ACCESS_PT_MINUT_ID=A.ACCESS_PT_MINUT_ID)
  WHEN MATCHED THEN UPDATE
  SET ACCESS_PT_UNAVL_IND=A.ACCESS_PT_UNAVL_IND,
  MOD_TS=CURRENT_TIMESTAMP(0)

  WHEN NOT MATCHED THEN INSERT
  (
   ACCESS_PT_ID ,
   ACCESS_PT_STAT_DT ,
   LOCN_NBR ,
   ACCESS_PT_MINUT_ID ,
   ACCESS_PT_UNAVL_IND ,
   DATASET_ID,
   CREAT_TS,
   MOD_TS
  )
  VALUES
  (
   A.ACCESS_PT_ID ,
   A.ACCESS_PT_STAT_DT ,
   A.LOCN_NBR ,
   A.ACCESS_PT_MINUT_ID ,
   A.ACCESS_PT_UNAVL_IND ,
   A.DATASET_ID,
   A.CREAT_TS,
   A.MOD_TS
  );



%default CURRENT_DATE `date +%Y%m%d`;
%declare CURRENT_TIMESTAMP `date "+'%Y-%m-%d %H:%m:%S'"`


ACCESS_PT_AVAIL_MINUT_Target  = LOAD '/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_MINUT_TABLE_20170413/' USING PigStorage(',') AS 
    ( 
    ACCESS_PT_ID:CHARARRAY,
    ACCESS_PT_STAT_DT:CHARARRAY,
    LOCN_NBR:INT,
    ACCESS_PT_MINUT_ID:INT,
    ACCESS_PT_UNAVL_IND:CHARARRAY,
    DATASET_ID:INT,
    CREAT_TS:CHARARRAY,
    MOD_TS:CHARARRAY);

MINUTE_A = LOAD '/user/hive/warehouse/minut_a' USING PigStorage(',') AS
    (
     ACCESS_PT_ID:CHARARRAY,
     ACCESS_PT_STAT_DT:CHARARRAY,
     LOCN_NBR:INT,
     ACCESS_PT_MINUT_ID:INT,
     ACCESS_PT_UNAVL_IND:CHARARRAY,
     DATASET_ID:INT,
     CREAT_TS:CHARARRAY,
     MOD_TS:CHARARRAY);


LEFT_JOIN = JOIN ACCESS_PT_AVAIL_MINUT_Target BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ,ACCESS_PT_MINUT_ID ) left outer,MINUTE_A BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ,ACCESS_PT_MINUT_ID );

RIGHT_JOIN = JOIN ACCESS_PT_AVAIL_MINUT_Target BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ,ACCESS_PT_MINUT_ID )  right outer,MINUTE_A  BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ,ACCESS_PT_MINUT_ID ) ;


a = FOREACH LEFT_JOIN GENERATE  ACCESS_PT_AVAIL_MINUT_Target::ACCESS_PT_ID,
                                ACCESS_PT_AVAIL_MINUT_Target::ACCESS_PT_STAT_DT,
                                ACCESS_PT_AVAIL_MINUT_Target::LOCN_NBR,
                                ACCESS_PT_AVAIL_MINUT_Target::ACCESS_PT_MINUT_ID,
                                (MINUTE_A::ACCESS_PT_ID IS NULL ? ACCESS_PT_AVAIL_MINUT_Target::ACCESS_PT_UNAVL_IND  : MINUTE_A::ACCESS_PT_UNAVL_IND),
                                ACCESS_PT_AVAIL_MINUT_Target::DATASET_ID,
                                ACCESS_PT_AVAIL_MINUT_Target::CREAT_TS,
                                (MINUTE_A::ACCESS_PT_ID IS NULL ? ACCESS_PT_AVAIL_MINUT_Target::MOD_TS               : $CURRENT_TIMESTAMP);


INSERT_VALUES = filter RIGHT_JOIN  BY ACCESS_PT_AVAIL_MINUT_Target::ACCESS_PT_ID is null;


INSERT_NEW = foreach INSERT_VALUES  generate   MINUTE_A::ACCESS_PT_ID,
                                               MINUTE_A::ACCESS_PT_STAT_DT,
                                               MINUTE_A::LOCN_NBR,
                                               MINUTE_A::ACCESS_PT_MINUT_ID,
                                               MINUTE_A::ACCESS_PT_UNAVL_IND,
                                               MINUTE_A::DATASET_ID,                                                                                                                                                   MINUTE_A::CREAT_TS,        
                                               MINUTE_A::MOD_TS;

UNION_DATA = UNION INSERT_NEW,a;

STORE UNION_DATA into '/incoming/netwatch/availability/2017_04_18_april';

hadoop fs -mkdir -p "/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_MINUT_TABLE_BACKUP/"
hadoop fs -mv "/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_MINUT_TABLE_`yesterday +%Y%m%d`/"  "/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_MINUT_TABLE_BACKUP/"

SQOOP_USER=hshaik0
SQOOP_PSWD=salim123*
SQOOP_DRIVER="com.teradata.jdbc.TeraDriver"
hdp_server="trphada01" 
teradata_schema="database=STR_ANLYTCS_MART_TBLS"
HADOOP_SQOOP_OP="/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_MINUT_TABLE_`date +%Y%m%d`/"
CONNECTION_STRING="$hdp_server/$teradata_schema"

#CONNECTION_STRING="$HDP_SERVER/$TERADATA_SCHEMA"

sqoop import --verbose --username $SQOOP_USER \
             --password $SQOOP_PSWD --driver $SQOOP_DRIVER  \
             --connect jdbc:teradata://$CONNECTION_STRING \
             --query "SELECT * FROM STR_ANLYTCS_MART_TBLS.SHC_WIFI_ACC_PT_AVAIL_MINUT WHERE ACCESS_PT_STAT_DT > CURRENT_DATE-400 AND ACCESS_PT_ID IS NOT NULL AND ACCESS_PT_STAT_DT IS NOT NULL AND LOCN_NBR IS NOT NULL AND ACCESS_PT_MINUT_ID IS NOT NULL AND ACCESS_PT_UNAVL_IND IS NOT NULL AND DATASET_ID IS NOT NULL AND CREAT_TS IS NOT NULL AND \$CONDITIONS" \
             --target-dir $HADOOP_SQOOP_OP \
             -m 1   



drop table TMP_DLY_ACCESS_PT_AVAIL_TEMP;
drop table TMP_DLY_ACCESS_PT_AVAIL;
drop table TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL;
drop table SHC_WIFI_ACCESS_PT_AVAIL_VOLT;
drop table A;
drop table updated_values;
drop table SHC_WIFI_ACCESS_PT_AVAIL_left_join_A;
drop table non_updated_null_rows;
drop table non_updated_rows;
drop table UPDATED_FINAL;
drop table SHC_WIFI_ACCESS_PT_AVAIL_right_join_A;
drop table insert_null_rows;
drop table INSERT_FINAL;
drop table SHC_WIFI_ACCESS_PT_AVAIL_MERGE;


LOAD DATA LOCAL INPATH '/staging/netwatch/motorola/combined/availability_summary_combiner_${hiveconf:CURRENT_DATE}.txt' OVERWRITE INTO TABLE ${hiveconf:AVAIL_STAGING_INPUT_TABLE};

CREATE TABLE IF NOT EXISTS TMP_DLY_ACCESS_PT_AVAIL_TEMP AS 
SELECT ACCESS_PT_NM,
 STAT_DT,
 STR_NBR,
 ACCESS_PT_UNAVL_IND,
 sum(ACCESS_PT_UNAVL_MINUT_QTY) ACCESS_PT_UNAVL_MINUT_QTY,
 max(CREAT_TS) CREAT_TS
 from
 ${hiveconf:AVAIL_STAGING_INPUT_TABLE}
 GROUP BY
 ACCESS_PT_NM ,
 STAT_DT,
 STR_NBR,
 ACCESS_PT_UNAVL_IND;

CREATE TABLE IF NOT EXISTS TMP_DLY_ACCESS_PT_AVAIL AS SELECT ACCESS_PT_NM,STAT_DT,STR_NBR,ACCESS_PT_UNAVL_IND, ACCESS_PT_UNAVL_MINUT_QTY,CREAT_TS,CAST(SUBSTR(STR_NBR,2) AS INT) AS NEW_STR_NBR FROM TMP_DLY_ACCESS_PT_AVAIL_TEMP;

CREATE TABLE IF NOT EXISTS TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL AS SELECT ACCESS_PT_NM,STAT_DT,CONCAT(SUBSTR(STR_NBR,1,1),NEW_STR_NBR) AS STR_NBR,ACCESS_PT_UNAVL_IND,ACCESS_PT_UNAVL_MINUT_QTY,CREAT_TS FROM TMP_DLY_ACCESS_PT_AVAIL;

DROP INDEX PI_TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL ON TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL;

CREATE INDEX  PI_TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL ON TABLE TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL (STR_NBR ) AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'
WITH DEFERRED REBUILD;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_AVAIL_VOLT
AS SELECT STG.ACCESS_PT_NM ACCESS_PT_ID,
 STG.STAT_DT ACCESS_PT_STAT_DT,
 CASE WHEN LCN.LOCN_NBR IS NULL THEN -1 ELSE LCN.LOCN_NBR END LOCN_NBR,
 STG.ACCESS_PT_UNAVL_IND,
 STG.ACCESS_PT_UNAVL_MINUT_QTY ACCESS_PT_UNAVL_MINUT_QTY,
 (year(current_date) - 1900) * 10000 + (month(current_date) * 100) + day(current_date) AS DATASET_ID,
 STG.CREAT_TS,
 CAST(NULL AS TIMESTAMP) MOD_TS
 FROM TMP_DLY_ACCESS_PT_AVAIL_ORIGINAL STG LEFT OUTER JOIN ${hiveconf:REF_SHC_LOCATION_INPUT_TABLE} LCN
 ON CAST(SUBSTR(STG.STR_NBR,2) AS INT) =LCN.LOCN_NBR;

 DROP INDEX PI_SHC_WIFI_ACCESS_PT_AVAIL_VOLT ON SHC_WIFI_ACCESS_PT_AVAIL_VOLT;

 CREATE INDEX  PI_SHC_WIFI_ACCESS_PT_AVAIL_VOLT ON TABLE SHC_WIFI_ACCESS_PT_AVAIL_VOLT (LOCN_NBR ) AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'
 WITH DEFERRED REBUILD;

CREATE TABLE IF NOT EXISTS A AS
 SELECT CAST(ACCESS_PT_ID  AS varchar(25)) ,
 ACCESS_PT_STAT_DT ,
 LOCN_NBR ,
 CAST(ACCESS_PT_UNAVL_MINUT_QTY AS INT) ,
 ACCESS_PT_UNAVL_IND  ,
 DATASET_ID ,
 CREAT_TS ,
 MOD_TS
 FROM SHC_WIFI_ACCESS_PT_AVAIL_VOLT;

 DROP INDEX PI_A ON A;

 CREATE INDEX  PI_A ON TABLE A (ACCESS_PT_ID,LOCN_NBR,ACCESS_PT_STAT_DT ) AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'
 WITH DEFERRED REBUILD;

CREATE TABLE IF NOT EXISTS updated_values  AS select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr ,a.access_pt_unavl_minut_qty ,a.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,CURRENT_TIMESTAMP as mod_ts FROM ${hiveconf:AVAIL_TARGET_TABLE} TRGT,A a WHERE TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID AND TRGT.LOCN_NBR=a.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT;

CREATE TABLE IF NOT EXISTS  SHC_WIFI_ACCESS_PT_AVAIL_left_join_A as select TRGT.ACCESS_PT_ID,TRGT.LOCN_NBR,TRGT.ACCESS_PT_STAT_DT,a.access_pt_unavl_minut_qty,a.access_pt_unavl_ind,TRGT.dataset_id,TRGT.creat_ts,a.mod_ts FROM ${hiveconf:AVAIL_TARGET_TABLE} TRGT LEFT JOIN A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT);

CREATE TABLE IF NOT EXISTS non_updated_null_rows AS SELECT * from SHC_WIFI_ACCESS_PT_AVAIL_left_join_A WHERE access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS non_updated_rows as select TRGT.access_pt_id ,TRGT.access_pt_stat_dt,TRGT.locn_nbr,TRGT.access_pt_unavl_minut_qty,TRGT.access_pt_unavl_ind,TRGT.dataset_id ,TRGT.creat_ts ,TRGT.mod_ts FROM ${hiveconf:AVAIL_TARGET_TABLE} TRGT, non_updated_null_rows r WHERE TRGT.ACCESS_PT_ID=r.ACCESS_PT_ID AND TRGT.LOCN_NBR=r.LOCN_NBR AND TRGT.ACCESS_PT_STAT_DT=r.ACCESS_PT_STAT_DT AND TRGT.creat_ts=r.creat_ts AND TRGT.dataset_id=r.dataset_id;

CREATE TABLE IF NOT EXISTS UPDATED_FINAL as select * from updated_values union all select distinct *  from non_updated_rows;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_AVAIL_right_join_A AS  select a.ACCESS_PT_ID,a.LOCN_NBR,a.ACCESS_PT_STAT_DT,TRGT.access_pt_unavl_minut_qty,TRGT.access_pt_unavl_ind,a.dataset_id,a.creat_ts,TRGT.mod_ts FROM ${hiveconf:AVAIL_TARGET_TABLE} TRGT RIGHT JOIN A a on (TRGT.ACCESS_PT_ID=a.ACCESS_PT_ID and TRGT.LOCN_NBR=a.LOCN_NBR and TRGT.ACCESS_PT_STAT_DT=a.ACCESS_PT_STAT_DT);

CREATE TABLE IF NOT EXISTS insert_null_rows AS SELECT * FROM SHC_WIFI_ACCESS_PT_AVAIL_right_join_A where access_pt_unavl_ind IS NULL;

CREATE TABLE IF NOT EXISTS INSERT_FINAL AS SELECT  a.access_pt_id ,a.access_pt_stat_dt,a.locn_nbr ,a.access_pt_unavl_minut_qty ,a.access_pt_unavl_ind,a.dataset_id,a.creat_ts ,a.mod_ts FROM A a,insert_null_rows i WHERE a.ACCESS_PT_ID=i.ACCESS_PT_ID AND a.LOCN_NBR=i.LOCN_NBR AND a.ACCESS_PT_STAT_DT=i.ACCESS_PT_STAT_DT AND a.creat_ts=i.creat_ts;

CREATE TABLE IF NOT EXISTS SHC_WIFI_ACCESS_PT_AVAIL_MERGE  AS  SELECT * FROM  updated_values union all select distinct *  from non_updated_rows UNION ALL SELECT  distinct * FROM INSERT_FINAL;



 Final netwatch project Pig 
 
 %default CURRENT_DATE `date +%Y%m%d`;
%declare CURRENT_TIMESTAMP `date "+'%Y-%m-%d %H:%m:%S'"`

ACCESS_PT_AVAIL_Target  = LOAD '/incoming/netwatch/availability/SHC_WIFI_ACCESS_PT_AVAIL_TABLE_20170413/' USING PigStorage(',') AS 
    ( 
    ACCESS_PT_ID:CHARARRAY,
    ACCESS_PT_STAT_DT:CHARARRAY,
    LOCN_NBR:INT,
    ACCESS_PT_UNAVL_MINUT_QTY :INT,
    ACCESS_PT_UNAVL_IND:CHARARRAY,
    DATASET_ID:INT,
    CREAT_TS:CHARARRAY,
    MOD_TS:CHARARRAY);

AVAIL_A = LOAD '/user/hive/warehouse/a' USING PigStorage(',') AS
    (
     ACCESS_PT_ID:CHARARRAY,
     ACCESS_PT_STAT_DT:CHARARRAY,
     LOCN_NBR:INT,
     ACCESS_PT_UNAVL_MINUT_QTY:INT,
     ACCESS_PT_UNAVL_IND:CHARARRAY,
     DATASET_ID:INT,
     CREAT_TS:CHARARRAY,
     MOD_TS:CHARARRAY);

INNER_JOIN = JOIN ACCESS_PT_AVAIL_Target BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR)            ,AVAIL_A BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR );

LEFT_JOIN  = JOIN ACCESS_PT_AVAIL_Target BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ) left outer,AVAIL_A BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR );

RIGHT_JOIN = JOIN ACCESS_PT_AVAIL_Target BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR)  right outer,AVAIL_A  BY (ACCESS_PT_ID ,ACCESS_PT_STAT_DT ,LOCN_NBR ) ;


a = FOREACH LEFT_JOIN GENERATE  ACCESS_PT_AVAIL_Target::ACCESS_PT_ID,
  ACCESS_PT_AVAIL_Target::ACCESS_PT_STAT_DT,
  ACCESS_PT_AVAIL_Target::LOCN_NBR,
  (AVAIL_A::ACCESS_PT_ID IS NULL ? ACCESS_PT_AVAIL_Target::ACCESS_PT_UNAVL_MINUT_QTY: AVAIL_A::ACCESS_PT_UNAVL_MINUT_QTY),
  (AVAIL_A::ACCESS_PT_ID IS NULL ? ACCESS_PT_AVAIL_Target::ACCESS_PT_UNAVL_IND: AVAIL_A::ACCESS_PT_UNAVL_IND),
  ACCESS_PT_AVAIL_Target::DATASET_ID,
  ACCESS_PT_AVAIL_Target::CREAT_TS,
  (AVAIL_A::ACCESS_PT_ID IS NULL ? ACCESS_PT_AVAIL_Target::MOD_TS:$CURRENT_TIMESTAMP);

INSERT_VALUES = filter RIGHT_JOIN  BY ACCESS_PT_AVAIL_Target::ACCESS_PT_ID is null;


INSERT_NEW = foreach INSERT_VALUES  generate   AVAIL_A::ACCESS_PT_ID,
                                               AVAIL_A::ACCESS_PT_STAT_DT,
                                               AVAIL_A::LOCN_NBR,
                                               AVAIL_A::ACCESS_PT_UNAVL_MINUT_QTY,
                                               AVAIL_A::ACCESS_PT_UNAVL_IND,
                                               AVAIL_A::DATASET_ID,                                                                                                                                                    AVAIL_A::CREAT_TS,        
                                               AVAIL_A::MOD_TS;

describe INSERT_NEW;
describe a;

UNION_DATA = UNION INSERT_NEW,a;
--DUMP UNION_DATA;


STORE UNION_DATA into '/incoming/netwatch/availability/UPDATEDVALUES_2017_04_22';

********************************************************************************************
set  hive.auto.convert.join=true
set hive.mapjoin.smalltable.filesize=30

LOAD DATA LOCAL INPATH '/staging/netwatch/motorola/combined/availability_summary_combiner_20170413.txt' OVERWRITE INTO TABLE ${hiveconf:AVAIL_STAGING_INPUT_TABLE};

 drop table TMP_acc_pt_down_tm;
 drop table TMP_acc_pt_minut_brk_dn;
 drop table MINUT_A;
 drop table updated_values_minut;
 drop table SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A;
 drop table non_updated_null_rows_minut;
 drop table non_updated_rows_minut;
 drop table UPDATED_FINAL_MINUT;
 drop table SHC_WIFI_ACCESS_PT_MINUT_AVAIL_right_join_A;
 drop table insert_null_rows_minut;
 drop table INSERT_FINAL_MINUT;
 drop table  SHC_WIFI_ACCESS_PT_MINUT_AVAIL_MERGE;
 drop table SHC_WIFI_ACCESS_PT_MINUT_AVAIL_left_join_A_without_map;


CREATE TABLE  IF NOT EXISTS TMP_acc_pt_down_tm  as
 SELECT ROW_NUMBER() OVER(ORDER BY a.STAT_DT ,
   a.STR_NBR ,
   a.ACCESS_PT_NM ,
   a.ACCESS_PT_UNAVL_IND ,
   a.ACCESS_PT_UNAVL_MINUT_QTY ,a.OUTAGE_BEG_TM,a.OUTAGE_END_TM ) row_num,
   a.STAT_DT ,
   a.STR_NBR ,
   a.ACCESS_PT_NM ,
   a.ACCESS_PT_UNAVL_IND ,
   a.ACCESS_PT_UNAVL_MINUT_QTY ,
   CAST( from_unixtime(unix_timestamp(OUTAGE_BEG_TM),'hh:MM a') AS CHAR(20)) OUTAGE_BEG_TM,
   CAST( from_unixtime(unix_timestamp(OUTAGE_END_TM),'hh:MM a') AS CHAR(20)) OUTAGE_END_TM ,
   B.ACCESS_PT_MINUT_DESC START_MINUT_DESC,
   B.ACCESS_PT_MINUT_ID START_MINUT_ID,
   C.ACCESS_PT_MINUT_DESC END_MINUT_DESC,
   C.ACCESS_PT_MINUT_ID END_MINUT_ID
   FROM ${hiveconf:AVAIL_STAGING_INPUT_TABLE} a,
   ${hiveconf:LU_DEJ_MINUT_ID_TABLE} b,
   ${hiveconf:LU_DEJ_MINUT_ID_TABLE} c
   WHERE a.ACCESS_PT_UNAVL_MINUT_QTY >0
   AND  CAST( from_unixtime(unix_timestamp(OUTAGE_BEG_TM),'hh:MM a') AS CHAR(20)) = b.ACCESS_PT_MINUT_DESC
   AND  CAST( from_unixtime(unix_timestamp(OUTAGE_END_TM),'hh:MM a') AS CHAR(20)) = c.ACCESS_PT_MINUT_DESC;


    CREATE TABLE IF NOT EXISTS TMP_acc_pt_minut_brk_dn
    AS
     SELECT
     ACCESS_PT_ID,
     ACCESS_PT_STAT_DT,
     CAST(SUBSTR(LOCN_NBR,2) AS INT) LOCN_NBR,
     CAST(ACCESS_PT_MINUT_ID AS SMALLINT) ACCESS_PT_MINUT_ID,
     CAST(ACCESS_PT_UNAVL_IND AS CHAR(1) ) ACCESS_PT_UNAVL_IND,
     (year(CURRENT_DATE) - 1900) * 10000 + (month(CURRENT_DATE) * 100) + day(CURRENT_DATE) DATASET_ID,
     CURRENT_TIMESTAMP CREAT_TS,
     CURRENT_TIMESTAMP MOD_TS
     FROM
     (
      SELECT DISTINCT
      a.row_num,
      a.ACCESS_PT_NM ACCESS_PT_ID,
      a.STAT_DT ACCESS_PT_STAT_DT,
      a.STR_NBR LOCN_NBR,
      b.ACCESS_PT_MINUT_ID ACCESS_PT_MINUT_ID,
      '1' ACCESS_PT_UNAVL_IND
      FROM
      TMP_acc_pt_down_tm a,
      ${hiveconf:LU_DEJ_MINUT_ID_TABLE} b
      WHERE
      b.ACCESS_PT_MINUT_ID BETWEEN a.START_MINUT_ID AND a.end_MINUT_ID
     )a ;

CREATE TABLE IF NOT EXISTS MINUT_A  AS 
    SELECT
    ACCESS_PT_ID ,
    ACCESS_PT_STAT_DT,
    LOCN_NBR ,
    ACCESS_PT_MINUT_ID ,
    ACCESS_PT_UNAVL_IND ,
    DATASET_ID,
    CREAT_TS,
    MOD_TS
    FROM
    TMP_acc_pt_minut_brk_dn;



